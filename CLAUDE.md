# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Facial Emotion Recognition (FER) system trained on the RAF-DB dataset. Classifies 7 emotions from facial images using VGG16 transfer learning, served via a FastAPI REST API with a vanilla JS frontend and an interactive Streamlit chatbot.

## Running the Project

```bash
# Start the FastAPI inference API (loads models/model_raf.h5 on startup)
python app_fastapi.py
# Runs on 0.0.0.0:5000

# Alternative : API Flask
python app.py
# Runs on 0.0.0.0:5000

# Verify GPU/TensorFlow setup
python test/testgpu.py

# Open index.html directly in a browser (requires the API to be running)

# Streamlit chatbot â€” camera + file upload (requires the API to be running)
pip install streamlit requests
streamlit run streamlit_app.py
# Runs on 0.0.0.0:8501
```

The web UI (`index.html`) calls `http://localhost:5000/predict` via `fetch`. The API accepts a `multipart/form-data` POST with a `file` field and returns JSON.

## Environment

The devcontainer uses `nvcr.io/nvidia/tensorflow:25.02-tf2-py3` with `--gpus all`. Key version constraints from `postCreateCommand`:
- `numpy<2.0.0` (confirmed 1.26.4)
- `scipy<1.13.0`
- `opencv-python-headless<4.10`

The DATASET directory is bind-mounted from the host (`c:/ProjetIA/raf-db/DATASET` â†’ `/workspace/DATASET`).

## Project Structure

```
raf-db/
â”œâ”€â”€ app_fastapi.py          # API FastAPI principale (inference) â€” Ã  utiliser
â”œâ”€â”€ app.py                  # API Flask alternative
â”œâ”€â”€ streamlit_app.py        # Chatbot Streamlit (camÃ©ra + upload fichier)
â”œâ”€â”€ index.html              # Frontend vanilla JS
â”œâ”€â”€ CLAUDE.md
â”‚
â”œâ”€â”€ css/                    # Feuilles de style
â”‚   â””â”€â”€ style.css           # Styles du frontend (extrait de index.html)
â”‚
â”œâ”€â”€ models/                 # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ model_raf.h5        # ModÃ¨le principal (196 MB, suivi via Git LFS)
â”‚
â”œâ”€â”€ notebooks/              # Notebooks d'entraÃ®nement
â”‚   â”œâ”€â”€ raf transfert VGG16.ipynb     # Principal â€” VGG16 fine-tuning (meilleurs rÃ©sultats)
â”‚   â”œâ”€â”€ raf transfert.ipynb           # Autres expÃ©riences de transfer learning
â”‚   â”œâ”€â”€ raf simple.ipynb              # Baseline CNN from scratch
â”‚   â”œâ”€â”€ raf augmentation.ipynb        # Exploration de l'augmentation de donnÃ©es
â”‚   â””â”€â”€ raf poid.ipynb                # ExpÃ©riences de pondÃ©ration des classes
â”‚
â”œâ”€â”€ results/                # Graphiques et matrices gÃ©nÃ©rÃ©s lors de l'entraÃ®nement
â”‚   â”œâ”€â”€ accuracy.png
â”‚   â”œâ”€â”€ distribution_emotions.png
â”‚   â”œâ”€â”€ matricec.png
â”‚   â”œâ”€â”€ model.png
â”‚   â”œâ”€â”€ output accuracy augm.png
â”‚   â””â”€â”€ outputcurrancy poid.png
â”‚
â”œâ”€â”€ samples/                # Images de test manuelles (dÃ©mo)
â”‚
â”œâ”€â”€ test/                   # Scripts de vÃ©rification
â”‚   â””â”€â”€ testgpu.py          # VÃ©rifie la dÃ©tection GPU par TensorFlow
â”‚
â”œâ”€â”€ doc/                    # Documentation du projet
â”‚   â”œâ”€â”€ presentation.docx
â”‚   â””â”€â”€ 2026-01-28 19-07-03.mp4
â”‚
â””â”€â”€ DATASET/                # Dataset RAF-DB (bind-mount depuis l'hÃ´te)
    â”œâ”€â”€ train/              # Sous-dossiers 1â€“7 (label Ã©motion), 12 271 images
    â”œâ”€â”€ test/               # Sous-dossiers 1â€“7, 3 068 images
    â”œâ”€â”€ train_labels.csv
    â””â”€â”€ test_labels.csv
```

## Architecture

### Inference Pipeline (`app_fastapi.py`)
1. Au dÃ©marrage (lifespan) : charge `models/model_raf.h5` et le Haar Cascade OpenCV
2. `POST /predict` : dÃ©code l'image â†’ dÃ©tection visages en niveaux de gris (`detectMultiScale(gray, 1.1, 5)`) â†’ regroupe tous les visages en un batch â†’ un seul appel `model.predict()` â†’ retourne classe + confiance pour chaque visage
3. RÃ©ponse : `{ "faces_detected": N, "predictions": [{ "emotion", "confidence", "box" }] }`

### Streamlit Chatbot (`streamlit_app.py`)
- Message de bienvenue expliquant l'app et les 7 Ã©motions
- Choix du mode : ðŸ“· camÃ©ra ou ðŸ“ upload fichier (JPG, PNG, WEBP)
- AprÃ¨s analyse : boutons **Continuer** (mÃªme mode) et **Changer de mode**
- `confidence` renvoyÃ©e par l'API dÃ©jÃ  en pourcentage (0â€“100), ne pas multiplier par 100
- Layout colorÃ© via CSS injectÃ© (`st.markdown`) â€” fond dÃ©gradÃ© bleu nuit, cadre cyan
- Cadre chatbot ciblÃ© via `st.container(border=True, key="chatbot")` â†’ `.st-key-chatbot` en CSS

### Emotion Classes
Indexed 0â€“6, mapped from RAF-DB labels 1â€“7:
`['Surprise', 'Peur', 'DÃ©goÃ»t', 'Joie', 'Tristesse', 'ColÃ¨re', 'Neutre']`

Class imbalance is significant: Joie has 1,185 test samples vs. Peur with 74.

### Model Architecture (from `notebooks/raf transfert VGG16.ipynb`)
- VGG16 base (ImageNet weights, all layers unfrozen for fine-tuning)
- Custom head: Flatten â†’ Dense(512, relu) + BatchNorm â†’ Dropout(0.5) â†’ Dense(7, softmax)
- Input: 100Ã—100 RGB images
- Training: Adam(lr=1e-4), sparse_categorical_crossentropy, EarlyStopping(patience=8), ReduceLROnPlateau
- Achieved ~82.4% weighted accuracy; Joie F1=0.93, DÃ©goÃ»t F1=0.41 (minority class)

Training notebooks use `ImageDataGenerator.flow_from_dataframe` with 18 workers and multiprocessing.
