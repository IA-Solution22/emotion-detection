<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DÃ©tecteur d'Ã‰motions IA â€“ RAF-DB</title>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>

<header>
  <h1>ğŸ­ DÃ©tecteur d'Ã‰motions Faciales</h1>
  <p>SystÃ¨me d'intelligence artificielle capable de reconnaÃ®tre les Ã©motions humaines Ã  partir d'une photo, en temps rÃ©el.</p>
  <span class="badge">Projet IA Â· RAF-DB Â· VGG16 Transfer Learning</span>
</header>

<main>

  <!-- DÃ‰MO -->
  <section>
    <h2>DÃ©mo</h2>
    <div class="card">
      <div class="demo-inner">
        <input type="file" id="imageInput" accept="image/*">
        <img id="preview" src="#" alt="AperÃ§u">
        <button class="btn" id="uploadBtn">Analyser l'image</button>
        <div id="results">Les rÃ©sultats s'afficheront ici...</div>
      </div>
    </div>
  </section>

  <!-- PRÃ‰SENTATION -->
  <section>
    <h2>PrÃ©sentation du projet</h2>
    <div class="card">
      <p>
        Ce projet est un systÃ¨me de <strong>reconnaissance automatique des Ã©motions faciales</strong>.
        Ã€ partir d'une simple photo, il dÃ©tecte les visages prÃ©sents et prÃ©dit l'Ã©motion dominante de chaque personne
        avec un degrÃ© de confiance associÃ©.
      </p>
      <p>
        Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur le dataset <strong>RAF-DB</strong> (Real-world Affective Faces Database),
        une base de donnÃ©es de rÃ©fÃ©rence dans le domaine, composÃ©e de plus de <strong>15 000 images</strong>
        de visages annotÃ©es par des humains selon 7 Ã©motions de base.
      </p>
      <p style="margin-bottom:0;">
        La prÃ©cision globale atteinte est de <strong>82,4 %</strong> sur les donnÃ©es de test â€”
        un rÃ©sultat compÃ©titif pour ce type de tÃ¢che sur un dataset en conditions rÃ©elles.
      </p>
    </div>
  </section>

  <!-- Ã‰MOTIONS RECONNUES -->
  <section>
    <h2>Ã‰motions reconnues</h2>
    <div class="emotion-grid">
      <div class="emotion-card">
        <span class="emoji">ğŸ˜®</span>
        <div class="name">Surprise</div>
        <div class="score">F1 : 83 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ğŸ˜¨</span>
        <div class="name">Peur</div>
        <div class="score">F1 : 63 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ğŸ¤¢</span>
        <div class="name">DÃ©goÃ»t</div>
        <div class="score">F1 : 41 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ğŸ˜„</span>
        <div class="name">Joie</div>
        <div class="score">F1 : 93 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ğŸ˜¢</span>
        <div class="name">Tristesse</div>
        <div class="score">F1 : 75 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ğŸ˜ </span>
        <div class="name">ColÃ¨re</div>
        <div class="score">F1 : 70 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ğŸ˜</span>
        <div class="name">Neutre</div>
        <div class="score">F1 : 79 %</div>
      </div>
    </div>
    <p style="margin-top:14px; font-size:.88rem; color:var(--muted);">
      Le score F1 mesure la qualitÃ© de reconnaissance pour chaque Ã©motion (prÃ©cision + rappel).
      Les Ã©motions peu reprÃ©sentÃ©es dans le dataset (Peur, DÃ©goÃ»t) sont naturellement plus difficiles Ã  reconnaÃ®tre.
    </p>
  </section>

  <!-- COMMENT Ã‡A MARCHE -->
  <section>
    <h2>Comment Ã§a marche ?</h2>
    <div class="pipeline card">
      <div class="pipe-step">ğŸ“· Image</div>
      <span class="pipe-arrow">â†’</span>
      <div class="pipe-step">ğŸ” DÃ©tection<br>des visages</div>
      <span class="pipe-arrow">â†’</span>
      <div class="pipe-step">âœ‚ï¸ DÃ©coupage<br>& redimensionnement</div>
      <span class="pipe-arrow">â†’</span>
      <div class="pipe-step">ğŸ§  ModÃ¨le IA<br>(VGG16)</div>
      <span class="pipe-arrow">â†’</span>
      <div class="pipe-step">ğŸ“Š RÃ©sultat</div>
    </div>
    <div class="steps card" style="padding: 8px 24px;">
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>DÃ©tection des visages</strong>
          Un algorithme de vision par ordinateur (Haar Cascade d'OpenCV) localise automatiquement tous les visages dans l'image, quelle que soit leur position ou taille.
        </div>
      </div>
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>PrÃ©traitement</strong>
          Chaque visage est dÃ©coupÃ©, redimensionnÃ© en 100Ã—100 pixels et normalisÃ© selon les standards de VGG16.
        </div>
      </div>
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>InfÃ©rence par le rÃ©seau de neurones</strong>
          Le modÃ¨le analyse les caractÃ©ristiques visuelles du visage et calcule une probabilitÃ© pour chacune des 7 Ã©motions.
        </div>
      </div>
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>RÃ©sultat</strong>
          L'Ã©motion avec la probabilitÃ© la plus haute est retournÃ©e avec son pourcentage de confiance.
        </div>
      </div>
    </div>
  </section>

  <!-- ARCHITECTURE TECHNIQUE -->
  <section>
    <h2>Architecture technique</h2>
    <h3>ModÃ¨le d'intelligence artificielle</h3>
    <div class="card">
      <p>
        Le modÃ¨le repose sur <strong>VGG16</strong>, un rÃ©seau de neurones convolutif prÃ©-entraÃ®nÃ© sur ImageNet
        (plus de 14 millions d'images). Cette technique, appelÃ©e <em>transfer learning</em>, permet
        de bÃ©nÃ©ficier des capacitÃ©s d'extraction visuelle d'un modÃ¨le gÃ©nÃ©raliste et de les spÃ©cialiser
        sur la reconnaissance d'Ã©motions.
      </p>
      <p style="margin-bottom:0;">
        Une tÃªte de classification personnalisÃ©e a Ã©tÃ© ajoutÃ©e et le modÃ¨le complet a Ã©tÃ© rÃ©-entraÃ®nÃ©
        (fine-tuning) sur RAF-DB pendant 50 epochs avec arrÃªt anticipÃ©.
      </p>
    </div>
    <h3>Stack technologique</h3>
    <ul class="tech-list">
      <li>Python 3.10</li>
      <li>TensorFlow 2 / Keras</li>
      <li>VGG16 (ImageNet)</li>
      <li>OpenCV</li>
      <li>FastAPI</li>
      <li>Uvicorn</li>
      <li>NumPy</li>
      <li>Docker (NVIDIA)</li>
      <li>RAF-DB Dataset</li>
    </ul>
  </section>

  <!-- PERFORMANCES -->
  <section>
    <h2>Performances du modÃ¨le</h2>
    <div class="card" style="padding:0; overflow:hidden;">
      <table>
        <thead>
          <tr>
            <th>Ã‰motion</th>
            <th>Score F1</th>
            <th>Visualisation</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>ğŸ˜„ Joie</td>
            <td><strong>93 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:93%"></div></div></td>
          </tr>
          <tr>
            <td>ğŸ˜® Surprise</td>
            <td><strong>83 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:83%"></div></div></td>
          </tr>
          <tr>
            <td>ğŸ˜ Neutre</td>
            <td><strong>79 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:79%"></div></div></td>
          </tr>
          <tr>
            <td>ğŸ˜¢ Tristesse</td>
            <td><strong>75 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:75%"></div></div></td>
          </tr>
          <tr>
            <td>ğŸ˜  ColÃ¨re</td>
            <td><strong>70 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:70%"></div></div></td>
          </tr>
          <tr>
            <td>ğŸ˜¨ Peur</td>
            <td><strong>63 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:63%"></div></div></td>
          </tr>
          <tr>
            <td>ğŸ¤¢ DÃ©goÃ»t</td>
            <td><strong>41 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:41%"></div></div></td>
          </tr>
        </tbody>
      </table>
    </div>
    <p style="font-size:.88rem; color:var(--muted); margin-top:10px;">
      <strong>PrÃ©cision globale : 82,4 %</strong> (moyenne pondÃ©rÃ©e sur 3 068 images de test).
      Les scores plus faibles sur Peur et DÃ©goÃ»t s'expliquent par le faible nombre d'exemples
      d'entraÃ®nement disponibles pour ces classes (respectivement 74 et 160 images).
    </p>
  </section>

</main>

<footer>
  Projet de reconnaissance d'Ã©motions faciales Â· EntraÃ®nÃ© sur RAF-DB Â· ModÃ¨le VGG16 Transfer Learning
</footer>

<script>
  // â”€â”€ RÃ©fÃ©rences DOM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const imageInput = document.getElementById('imageInput');
  const preview    = document.getElementById('preview');
  const uploadBtn  = document.getElementById('uploadBtn');
  const resultsDiv = document.getElementById('results');

  // â”€â”€ AperÃ§u de l'image sÃ©lectionnÃ©e â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // DÃ¨s qu'un fichier est choisi, on l'affiche en aperÃ§u sans l'envoyer
  imageInput.onchange = () => {
    const [file] = imageInput.files;
    if (file) {
      preview.src = URL.createObjectURL(file);
      preview.style.display = 'block';
    }
  };

  // â”€â”€ Envoi de l'image Ã  l'API et affichage des rÃ©sultats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  uploadBtn.onclick = async () => {
    const file = imageInput.files[0];
    if (!file) return alert("Choisis une image d'abord !");

    // Construire un objet FormData pour l'envoi multipart/form-data
    const formData = new FormData();
    formData.append('file', file);

    // DÃ©sactiver le bouton pendant l'appel pour Ã©viter les doubles envois
    uploadBtn.disabled = true;
    resultsDiv.innerHTML = "âŒ› Analyse en cours...";

    try {
      // Appel POST vers l'API Flask (doit Ãªtre dÃ©marrÃ©e avec python app.py)
      const response = await fetch('http://localhost:5000/predict', {
        method: 'POST',
        body: formData
      });

      // VÃ©rifier que l'API a rÃ©pondu avec un statut HTTP succÃ¨s (2xx)
      if (!response.ok) {
        const err = await response.json().catch(() => ({}));
        resultsDiv.innerHTML = `âŒ Erreur API (${response.status}) : ${err.error || err.detail || 'inconnue'}`;
        return;
      }

      const data = await response.json();

      // Afficher les prÃ©dictions si au moins un visage a Ã©tÃ© dÃ©tectÃ©
      if (data.faces_detected > 0) {
        let html = `<strong>${data.faces_detected} visage(s) trouvÃ©(s) :</strong><br>`;
        data.predictions.forEach(p => {
          html += `<p>â€¢ Ã‰motion : <span class="emotion-tag">${p.emotion}</span> (${p.confidence}%)</p>`;
        });
        resultsDiv.innerHTML = html;
      } else {
        resultsDiv.innerHTML = "âŒ Aucun visage dÃ©tectÃ©.";
      }

    } catch (error) {
      // L'API est inaccessible (non dÃ©marrÃ©e, mauvais port, etc.)
      resultsDiv.innerHTML = "âŒ Erreur de connexion Ã  l'API.";
      console.error(error);
    } finally {
      // Toujours rÃ©activer le bouton, que la requÃªte ait rÃ©ussi ou non
      uploadBtn.disabled = false;
    }
  };
</script>
</body>
</html>
