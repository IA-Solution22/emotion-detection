<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>D√©tecteur d'√âmotions IA ‚Äì RAF-DB</title>
  <style>
    :root {
      --accent: #4a90e2;
      --accent-dark: #2c6fbe;
      --bg: #f7f8fc;
      --card: #ffffff;
      --text: #2d2d2d;
      --muted: #6b7280;
      --border: #e5e7eb;
      --tag-bg: #e8f0fc;
    }

    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: 'Segoe UI', system-ui, sans-serif;
      background: var(--bg);
      color: var(--text);
      line-height: 1.7;
    }

    /* ‚îÄ‚îÄ HEADER ‚îÄ‚îÄ */
    header {
      background: linear-gradient(135deg, #1e3a5f 0%, #4a90e2 100%);
      color: white;
      padding: 64px 24px 48px;
      text-align: center;
    }
    header h1 { font-size: 2.4rem; font-weight: 700; margin-bottom: 12px; }
    header p  { font-size: 1.1rem; opacity: .85; max-width: 600px; margin: 0 auto; }
    .badge {
      display: inline-block;
      background: rgba(255,255,255,.2);
      border: 1px solid rgba(255,255,255,.35);
      border-radius: 99px;
      padding: 4px 14px;
      font-size: .8rem;
      margin-top: 18px;
      letter-spacing: .04em;
    }

    /* ‚îÄ‚îÄ LAYOUT ‚îÄ‚îÄ */
    main {
      max-width: 860px;
      margin: 0 auto;
      padding: 48px 24px 80px;
    }

    section { margin-bottom: 56px; }

    h2 {
      font-size: 1.5rem;
      font-weight: 700;
      color: var(--accent-dark);
      border-left: 4px solid var(--accent);
      padding-left: 12px;
      margin-bottom: 20px;
    }

    h3 {
      font-size: 1.05rem;
      font-weight: 600;
      margin: 24px 0 8px;
      color: var(--text);
    }

    p { margin-bottom: 14px; }

    /* ‚îÄ‚îÄ CARDS ‚îÄ‚îÄ */
    .card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 24px;
      margin-bottom: 16px;
      box-shadow: 0 1px 4px rgba(0,0,0,.06);
    }

    /* ‚îÄ‚îÄ DEMO WIDGET ‚îÄ‚îÄ */
    .demo-inner {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 14px;
    }
    #preview {
      max-width: 100%;
      max-height: 280px;
      border-radius: 8px;
      display: none;
      border: 1px solid var(--border);
    }
    .btn {
      background: var(--accent);
      color: white;
      border: none;
      padding: 10px 28px;
      border-radius: 6px;
      cursor: pointer;
      font-size: .95rem;
      font-weight: 600;
      transition: background .2s;
    }
    .btn:hover { background: var(--accent-dark); }
    .btn:disabled { background: #ccc; cursor: default; }
    #results {
      width: 100%;
      background: #f1f5f9;
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 12px 16px;
      font-family: monospace;
      font-size: .88rem;
      min-height: 48px;
    }
    .emotion-tag { font-weight: bold; color: #d9534f; }

    /* ‚îÄ‚îÄ STEPS ‚îÄ‚îÄ */
    .steps { counter-reset: step; }
    .step {
      display: flex;
      gap: 16px;
      align-items: flex-start;
      padding: 16px 0;
      border-bottom: 1px solid var(--border);
    }
    .step:last-child { border-bottom: none; }
    .step-num {
      counter-increment: step;
      flex-shrink: 0;
      width: 36px; height: 36px;
      background: var(--accent);
      color: white;
      border-radius: 50%;
      display: flex; align-items: center; justify-content: center;
      font-weight: 700;
      font-size: .95rem;
    }
    .step-num::after { content: counter(step); }
    .step-body strong { display: block; margin-bottom: 4px; }

    /* ‚îÄ‚îÄ EMOTIONS GRID ‚îÄ‚îÄ */
    .emotion-grid {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(110px, 1fr));
      gap: 12px;
    }
    .emotion-card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 10px;
      padding: 14px 10px;
      text-align: center;
      box-shadow: 0 1px 3px rgba(0,0,0,.05);
    }
    .emotion-card .emoji { font-size: 2rem; display: block; margin-bottom: 6px; }
    .emotion-card .name  { font-weight: 600; font-size: .85rem; }
    .emotion-card .score { font-size: .75rem; color: var(--muted); margin-top: 4px; }

    /* ‚îÄ‚îÄ TECH STACK ‚îÄ‚îÄ */
    .tech-list {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      padding: 0;
      list-style: none;
    }
    .tech-list li {
      background: var(--tag-bg);
      color: var(--accent-dark);
      border-radius: 6px;
      padding: 6px 14px;
      font-size: .85rem;
      font-weight: 500;
    }

    /* ‚îÄ‚îÄ PERF TABLE ‚îÄ‚îÄ */
    table { width: 100%; border-collapse: collapse; font-size: .9rem; }
    th { background: var(--accent); color: white; padding: 10px 14px; text-align: left; }
    td { padding: 9px 14px; border-bottom: 1px solid var(--border); }
    tr:last-child td { border-bottom: none; }
    tr:nth-child(even) td { background: #f8faff; }
    .bar-wrap { background: #e5e7eb; border-radius: 99px; height: 8px; width: 100%; margin-top: 4px; }
    .bar { background: var(--accent); height: 8px; border-radius: 99px; }

    /* ‚îÄ‚îÄ PIPELINE ‚îÄ‚îÄ */
    .pipeline {
      display: flex;
      align-items: center;
      flex-wrap: wrap;
      gap: 0;
      margin: 16px 0;
    }
    .pipe-step {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 10px 16px;
      font-size: .85rem;
      font-weight: 500;
      text-align: center;
      box-shadow: 0 1px 3px rgba(0,0,0,.06);
    }
    .pipe-arrow { color: var(--accent); font-size: 1.2rem; padding: 0 8px; font-weight: 700; }

    /* ‚îÄ‚îÄ FOOTER ‚îÄ‚îÄ */
    footer {
      text-align: center;
      padding: 32px;
      font-size: .82rem;
      color: var(--muted);
      border-top: 1px solid var(--border);
    }
  </style>
</head>
<body>

<header>
  <h1>üé≠ D√©tecteur d'√âmotions Faciales</h1>
  <p>Syst√®me d'intelligence artificielle capable de reconna√Ætre les √©motions humaines √† partir d'une photo, en temps r√©el.</p>
  <span class="badge">Projet IA ¬∑ RAF-DB ¬∑ VGG16 Transfer Learning</span>
</header>

<main>

  <!-- D√âMO -->
  <section>
    <h2>D√©mo</h2>
    <div class="card">
      <div class="demo-inner">
        <input type="file" id="imageInput" accept="image/*">
        <img id="preview" src="#" alt="Aper√ßu">
        <button class="btn" id="uploadBtn">Analyser l'image</button>
        <div id="results">Les r√©sultats s'afficheront ici...</div>
      </div>
    </div>
  </section>

  <!-- PR√âSENTATION -->
  <section>
    <h2>Pr√©sentation du projet</h2>
    <div class="card">
      <p>
        Ce projet est un syst√®me de <strong>reconnaissance automatique des √©motions faciales</strong>.
        √Ä partir d'une simple photo, il d√©tecte les visages pr√©sents et pr√©dit l'√©motion dominante de chaque personne
        avec un degr√© de confiance associ√©.
      </p>
      <p>
        Le mod√®le a √©t√© entra√Æn√© sur le dataset <strong>RAF-DB</strong> (Real-world Affective Faces Database),
        une base de donn√©es de r√©f√©rence dans le domaine, compos√©e de plus de <strong>15 000 images</strong>
        de visages annot√©es par des humains selon 7 √©motions de base.
      </p>
      <p style="margin-bottom:0;">
        La pr√©cision globale atteinte est de <strong>82,4 %</strong> sur les donn√©es de test ‚Äî
        un r√©sultat comp√©titif pour ce type de t√¢che sur un dataset en conditions r√©elles.
      </p>
    </div>
  </section>

  <!-- √âMOTIONS RECONNUES -->
  <section>
    <h2>√âmotions reconnues</h2>
    <div class="emotion-grid">
      <div class="emotion-card">
        <span class="emoji">üòÆ</span>
        <div class="name">Surprise</div>
        <div class="score">F1 : 83 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">üò®</span>
        <div class="name">Peur</div>
        <div class="score">F1 : 63 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">ü§¢</span>
        <div class="name">D√©go√ªt</div>
        <div class="score">F1 : 41 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">üòÑ</span>
        <div class="name">Joie</div>
        <div class="score">F1 : 93 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">üò¢</span>
        <div class="name">Tristesse</div>
        <div class="score">F1 : 75 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">üò†</span>
        <div class="name">Col√®re</div>
        <div class="score">F1 : 70 %</div>
      </div>
      <div class="emotion-card">
        <span class="emoji">üòê</span>
        <div class="name">Neutre</div>
        <div class="score">F1 : 79 %</div>
      </div>
    </div>
    <p style="margin-top:14px; font-size:.88rem; color:var(--muted);">
      Le score F1 mesure la qualit√© de reconnaissance pour chaque √©motion (pr√©cision + rappel).
      Les √©motions peu repr√©sent√©es dans le dataset (Peur, D√©go√ªt) sont naturellement plus difficiles √† reconna√Ætre.
    </p>
  </section>

  <!-- COMMENT √áA MARCHE -->
  <section>
    <h2>Comment √ßa marche ?</h2>
    <div class="pipeline card">
      <div class="pipe-step">üì∑ Image</div>
      <span class="pipe-arrow">‚Üí</span>
      <div class="pipe-step">üîç D√©tection<br>des visages</div>
      <span class="pipe-arrow">‚Üí</span>
      <div class="pipe-step">‚úÇÔ∏è D√©coupage<br>& redimensionnement</div>
      <span class="pipe-arrow">‚Üí</span>
      <div class="pipe-step">üß† Mod√®le IA<br>(VGG16)</div>
      <span class="pipe-arrow">‚Üí</span>
      <div class="pipe-step">üìä R√©sultat</div>
    </div>
    <div class="steps card" style="padding: 8px 24px;">
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>D√©tection des visages</strong>
          Un algorithme de vision par ordinateur (Haar Cascade d'OpenCV) localise automatiquement tous les visages dans l'image, quelle que soit leur position ou taille.
        </div>
      </div>
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>Pr√©traitement</strong>
          Chaque visage est d√©coup√©, redimensionn√© en 100√ó100 pixels et normalis√© selon les standards de VGG16.
        </div>
      </div>
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>Inf√©rence par le r√©seau de neurones</strong>
          Le mod√®le analyse les caract√©ristiques visuelles du visage et calcule une probabilit√© pour chacune des 7 √©motions.
        </div>
      </div>
      <div class="step">
        <div class="step-num"></div>
        <div class="step-body">
          <strong>R√©sultat</strong>
          L'√©motion avec la probabilit√© la plus haute est retourn√©e avec son pourcentage de confiance.
        </div>
      </div>
    </div>
  </section>

  <!-- ARCHITECTURE TECHNIQUE -->
  <section>
    <h2>Architecture technique</h2>
    <h3>Mod√®le d'intelligence artificielle</h3>
    <div class="card">
      <p>
        Le mod√®le repose sur <strong>VGG16</strong>, un r√©seau de neurones convolutif pr√©-entra√Æn√© sur ImageNet
        (plus de 14 millions d'images). Cette technique, appel√©e <em>transfer learning</em>, permet
        de b√©n√©ficier des capacit√©s d'extraction visuelle d'un mod√®le g√©n√©raliste et de les sp√©cialiser
        sur la reconnaissance d'√©motions.
      </p>
      <p style="margin-bottom:0;">
        Une t√™te de classification personnalis√©e a √©t√© ajout√©e et le mod√®le complet a √©t√© r√©-entra√Æn√©
        (fine-tuning) sur RAF-DB pendant 50 epochs avec arr√™t anticip√©.
      </p>
    </div>
    <h3>Stack technologique</h3>
    <ul class="tech-list">
      <li>Python 3.10</li>
      <li>TensorFlow 2 / Keras</li>
      <li>VGG16 (ImageNet)</li>
      <li>OpenCV</li>
      <li>FastAPI</li>
      <li>Uvicorn</li>
      <li>NumPy</li>
      <li>Docker (NVIDIA)</li>
      <li>RAF-DB Dataset</li>
    </ul>
  </section>

  <!-- PERFORMANCES -->
  <section>
    <h2>Performances du mod√®le</h2>
    <div class="card" style="padding:0; overflow:hidden;">
      <table>
        <thead>
          <tr>
            <th>√âmotion</th>
            <th>Score F1</th>
            <th>Visualisation</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>üòÑ Joie</td>
            <td><strong>93 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:93%"></div></div></td>
          </tr>
          <tr>
            <td>üòÆ Surprise</td>
            <td><strong>83 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:83%"></div></div></td>
          </tr>
          <tr>
            <td>üòê Neutre</td>
            <td><strong>79 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:79%"></div></div></td>
          </tr>
          <tr>
            <td>üò¢ Tristesse</td>
            <td><strong>75 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:75%"></div></div></td>
          </tr>
          <tr>
            <td>üò† Col√®re</td>
            <td><strong>70 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:70%"></div></div></td>
          </tr>
          <tr>
            <td>üò® Peur</td>
            <td><strong>63 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:63%"></div></div></td>
          </tr>
          <tr>
            <td>ü§¢ D√©go√ªt</td>
            <td><strong>41 %</strong></td>
            <td><div class="bar-wrap"><div class="bar" style="width:41%"></div></div></td>
          </tr>
        </tbody>
      </table>
    </div>
    <p style="font-size:.88rem; color:var(--muted); margin-top:10px;">
      <strong>Pr√©cision globale : 82,4 %</strong> (moyenne pond√©r√©e sur 3 068 images de test).
      Les scores plus faibles sur Peur et D√©go√ªt s'expliquent par le faible nombre d'exemples
      d'entra√Ænement disponibles pour ces classes (respectivement 74 et 160 images).
    </p>
  </section>

</main>

<footer>
  Projet de reconnaissance d'√©motions faciales ¬∑ Entra√Æn√© sur RAF-DB ¬∑ Mod√®le VGG16 Transfer Learning
</footer>

<script>
  // ‚îÄ‚îÄ R√©f√©rences DOM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  const imageInput = document.getElementById('imageInput');
  const preview    = document.getElementById('preview');
  const uploadBtn  = document.getElementById('uploadBtn');
  const resultsDiv = document.getElementById('results');

  // ‚îÄ‚îÄ Aper√ßu de l'image s√©lectionn√©e ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  // D√®s qu'un fichier est choisi, on l'affiche en aper√ßu sans l'envoyer
  imageInput.onchange = () => {
    const [file] = imageInput.files;
    if (file) {
      preview.src = URL.createObjectURL(file);
      preview.style.display = 'block';
    }
  };

  // ‚îÄ‚îÄ Envoi de l'image √† l'API et affichage des r√©sultats ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  uploadBtn.onclick = async () => {
    const file = imageInput.files[0];
    if (!file) return alert("Choisis une image d'abord !");

    // Construire un objet FormData pour l'envoi multipart/form-data
    const formData = new FormData();
    formData.append('file', file);

    // D√©sactiver le bouton pendant l'appel pour √©viter les doubles envois
    uploadBtn.disabled = true;
    resultsDiv.innerHTML = "‚åõ Analyse en cours...";

    try {
      // Appel POST vers l'API Flask (doit √™tre d√©marr√©e avec python app.py)
      const response = await fetch('http://localhost:5000/predict', {
        method: 'POST',
        body: formData
      });

      // V√©rifier que l'API a r√©pondu avec un statut HTTP succ√®s (2xx)
      if (!response.ok) {
        const err = await response.json().catch(() => ({}));
        resultsDiv.innerHTML = `‚ùå Erreur API (${response.status}) : ${err.error || err.detail || 'inconnue'}`;
        return;
      }

      const data = await response.json();

      // Afficher les pr√©dictions si au moins un visage a √©t√© d√©tect√©
      if (data.faces_detected > 0) {
        let html = `<strong>${data.faces_detected} visage(s) trouv√©(s) :</strong><br>`;
        data.predictions.forEach(p => {
          html += `<p>‚Ä¢ √âmotion : <span class="emotion-tag">${p.emotion}</span> (${p.confidence}%)</p>`;
        });
        resultsDiv.innerHTML = html;
      } else {
        resultsDiv.innerHTML = "‚ùå Aucun visage d√©tect√©.";
      }

    } catch (error) {
      // L'API est inaccessible (non d√©marr√©e, mauvais port, etc.)
      resultsDiv.innerHTML = "‚ùå Erreur de connexion √† l'API.";
      console.error(error);
    } finally {
      // Toujours r√©activer le bouton, que la requ√™te ait r√©ussi ou non
      uploadBtn.disabled = false;
    }
  };
</script>
</body>
</html>
